{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9e7a6f-43bd-473d-9a78-4a8078d6b1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "\n",
    "# 初始化MediaPipe Hands模块\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "# 打开摄像头\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "with mp_hands.Hands(\n",
    "    model_complexity=0,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5,\n",
    "    max_num_hands=2\n",
    ") as hands:\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            print(\"忽略空摄像头帧\")\n",
    "            continue\n",
    "        \n",
    "        # 转换颜色空间 BGR to RGB\n",
    "        image.flags.writeable = False\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # 处理手势检测\n",
    "        results = hands.process(image)\n",
    "        \n",
    "        # 绘制检测结果\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                # 绘制手部关键点和连接线\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image,\n",
    "                    hand_landmarks,\n",
    "                    mp_hands.HAND_CONNECTIONS,\n",
    "                    mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "                    mp_drawing_styles.get_default_hand_connections_style()\n",
    "                )\n",
    "        \n",
    "        # 水平翻转图像以获得自拍视图\n",
    "        image = cv2.flip(image, 1)\n",
    "        \n",
    "        # 显示提示信息\n",
    "        cv2.putText(image, \"按 'P' 打印坐标 | ESC退出\", (10, 30), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        \n",
    "        # 显示结果\n",
    "        cv2.imshow('MediaPipe Hands', image)\n",
    "        \n",
    "        key = cv2.waitKey(5)\n",
    "        # 按ESC退出\n",
    "        if key & 0xFF == 27:\n",
    "            break\n",
    "        # 按P打印坐标\n",
    "        elif key & 0xFF == ord('p') or key & 0xFF == ord('P'):\n",
    "            if results.multi_hand_landmarks:\n",
    "                print(\"\\n=== 手部关键点坐标 ===\")\n",
    "                for hand_idx, hand_landmarks in enumerate(results.multi_hand_landmarks):\n",
    "                    print(f\"\\n手 #{hand_idx + 1}:\")\n",
    "                    for landmark_idx, landmark in enumerate(hand_landmarks.landmark):\n",
    "                        print(f\"点 {landmark_idx}: (X: {landmark.x:.4f}, Y: {landmark.y:.4f}, Z: {landmark.z:.4f})\")\n",
    "                print(\"=====================\\n\")\n",
    "            else:\n",
    "                print(\"当前帧未检测到手部！\")\n",
    "\n",
    "# 释放资源\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de759f5-0883-4030-a7f5-42f74f83bfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "\n",
    "# 初始化MediaPipe手部模型\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=False, max_num_hands=1, min_detection_confidence=0.5)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# 假设摄像头的焦距（需根据实际摄像头标定，此处为示例值）\n",
    "FOCAL_LENGTH = 1000  # 单位：像素\n",
    "REAL_HAND_WIDTH = 0.09  # 成人手掌平均宽度（单位：米，约9cm）\n",
    "\n",
    "def estimate_depth(image, landmarks):\n",
    "    # 取手腕（0号点）和中指根部（9号点）的坐标\n",
    "    wrist = landmarks.landmark[0]\n",
    "    mid_finger = landmarks.landmark[9]\n",
    "    \n",
    "    # 计算两点在图像中的像素距离\n",
    "    image_height, image_width = image.shape[:2]\n",
    "    x1, y1 = int(wrist.x * image_width), int(wrist.y * image_height)\n",
    "    x2, y2 = int(mid_finger.x * image_width), int(mid_finger.y * image_height)\n",
    "    pixel_distance = np.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
    "    \n",
    "    # 通过相似三角形估算深度\n",
    "    depth = (REAL_HAND_WIDTH * FOCAL_LENGTH) / pixel_distance\n",
    "    return depth, (x1, y1, x2, y2)\n",
    "\n",
    "# 打开摄像头\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # 转换为RGB格式（MediaPipe需要）\n",
    "    image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(image_rgb)\n",
    "    \n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            # 估算深度并获取参考线坐标\n",
    "            depth, (x1, y1, x2, y2) = estimate_depth(frame, hand_landmarks)\n",
    "            \n",
    "            # 在图像上绘制手部关键点和参考线\n",
    "            mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "            cv2.line(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            \n",
    "            # 显示深度值\n",
    "            cv2.putText(frame, f\"Depth: {depth:.2f}m\", (10, 30), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "    \n",
    "    # 显示画面\n",
    "    cv2.imshow(\"Hand Tracking with Depth Estimation\", frame)\n",
    "    \n",
    "    # 按ESC退出\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "# 释放资源\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2123d0d2",
   "metadata": {},
   "source": [
    "T3. \n",
    " A test for calculating the distance for bending angles between all the 10 joints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d66a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "\n",
    "# 初始化MediaPipe手部模型\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=False, max_num_hands=1, min_detection_confidence=0.5)\n",
    "\n",
    "# 定义所有需要标注的关节角度（包括大拇指）\n",
    "JOINT_ANGLES = [\n",
    "    (1, 2, 3),   # 大拇指第一关节\n",
    "    (2, 3, 4),   # 大拇指第二关节\n",
    "    (5, 6, 7),   # 食指第一关节\n",
    "    (6, 7, 8),   # 食指第二关节\n",
    "    (9, 10, 11), # 中指第一关节\n",
    "    (10, 11, 12),# 中指第二关节\n",
    "    (13, 14, 15),# 无名指第一关节\n",
    "    (14, 15, 16),# 无名指第二关节\n",
    "    (17, 18, 19),# 小指第一关节\n",
    "    (18, 19, 20) # 小指第二关节\n",
    "]\n",
    "\n",
    "# 为每个角度定义偏移量，避免文字重叠\n",
    "ANGLE_OFFSETS = {\n",
    "    (1, 2, 3): (-40, 20),   # 大拇指第一关节\n",
    "    (2, 3, 4): (-40, -20),  # 大拇指第二关节\n",
    "    (5, 6, 7): (0, 30),     # 食指第一关节\n",
    "    (6, 7, 8): (0, -30),    # 食指第二关节\n",
    "    (9, 10, 11): (0, 30),   # 中指第一关节\n",
    "    (10, 11, 12): (0, -30), # 中指第二关节\n",
    "    (13, 14, 15): (0, 30),  # 无名指第一关节\n",
    "    (14, 15, 16): (0, -30), # 无名指第二关节\n",
    "    (17, 18, 19): (0, 30),  # 小指第一关节\n",
    "    (18, 19, 20): (0, -30)  # 小指第二关节\n",
    "}\n",
    "\n",
    "def calculate_angle(a, b, c):\n",
    "    \"\"\"计算三个点之间的夹角（单位：度）\"\"\"\n",
    "    a, b, c = np.array(a), np.array(b), np.array(c)\n",
    "    ba, bc = a - b, c - b\n",
    "    cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))\n",
    "    return np.degrees(np.arccos(np.clip(cosine_angle, -1, 1)))\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # 转换为RGB并处理\n",
    "    image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(image_rgb)\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            # 获取所有关键点的像素坐标\n",
    "            h, w = frame.shape[:2]\n",
    "            landmarks = [(int(lm.x * w), int(lm.y * h)) for lm in hand_landmarks.landmark]\n",
    "\n",
    "            # 绘制所有关节角度\n",
    "            for (i, j, k), offset in zip(JOINT_ANGLES, ANGLE_OFFSETS.values()):\n",
    "                if j < len(landmarks):\n",
    "                    angle = calculate_angle(landmarks[i], landmarks[j], landmarks[k])\n",
    "                    # 应用偏移量避免重叠\n",
    "                    text_pos = (landmarks[j][0] + offset[0], landmarks[j][1] + offset[1])\n",
    "                    # 为不同手指使用不同颜色\n",
    "                    color = (0, 200, 255) if i in [1,2,3,4] else (0, 255, 200)  # 大拇指橙色，其他青色\n",
    "                    cv2.putText(frame, f\"{angle:.0f}°\", text_pos, \n",
    "                              cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "\n",
    "    # 显示画面\n",
    "    cv2.imshow(\"Hand Joint Angles\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:  # ESC退出\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d58da0f",
   "metadata": {},
   "source": [
    "At this point, I started to think about how to use the angle as a weight for building the gesture recognition sample. The pain point is to figure the recognition for overlapping fingers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca612c3c",
   "metadata": {},
   "source": [
    "There are multiple ways to think about it. If we are using static images of overlapping fingers, we need the model to predict which finger is on top. If we are using video frames, we may predict from standard finger position to the overlapping state. We may use the video frame of one finger approaching the over finger to train a model, and make the prediction when there is a tendency for this motion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7019ae8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01ea875",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "\n",
    "# 初始化MediaPipe手部模型\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=True, max_num_hands=1, min_detection_confidence=0.7)\n",
    "\n",
    "# 指尖关键点索引\n",
    "FINGER_TIPS = {\n",
    "    \"thumb\": 4,\n",
    "    \"index\": 8,\n",
    "    \"middle\": 12,\n",
    "    \"ring\": 16,\n",
    "    \"pinky\": 20\n",
    "}\n",
    "\n",
    "def are_fingers_overlapping(finger1, finger2, landmarks, img_size, xy_threshold=0.05, z_threshold=0.1):\n",
    "    \"\"\"\n",
    "    判断两根手指是否重叠及上下关系\n",
    "    :param finger1: 手指1名称（如\"index\"）\n",
    "    :param finger2: 手指2名称（如\"middle\"）\n",
    "    :param landmarks: MediaPipe输出的手部关键点\n",
    "    :param img_size: 图像尺寸（宽,高）\n",
    "    :param xy_threshold: XY平面重叠阈值（归一化距离）\n",
    "    :param z_threshold: Z轴深度差异阈值\n",
    "    :return: (是否重叠, 上方手指名称)\n",
    "    \"\"\"\n",
    "    # 获取指尖的归一化坐标\n",
    "    tip1 = landmarks[FINGER_TIPS[finger1]]\n",
    "    tip2 = landmarks[FINGER_TIPS[finger2]]\n",
    "    \n",
    "    # 计算XY平面距离（像素单位）\n",
    "    w, h = img_size\n",
    "    xy_distance = np.sqrt(((tip1.x - tip2.x) * w)**2 + ((tip1.y - tip2.y) * h)**2)\n",
    "    xy_distance_normalized = xy_distance / max(w, h)\n",
    "    \n",
    "    # 如果XY距离超过阈值，直接返回不重叠\n",
    "    if xy_distance_normalized > xy_threshold:\n",
    "        return False, None\n",
    "    \n",
    "    # 比较Z轴深度（注意：MediaPipe的Z轴值越小越近）\n",
    "    if tip1.z < tip2.z - z_threshold:\n",
    "        return True, finger1  # finger1在上\n",
    "    elif tip2.z < tip1.z - z_threshold:\n",
    "        return True, finger2  # finger2在上\n",
    "    else:\n",
    "        return True, None  # 重叠但无法区分上下\n",
    "\n",
    "# 示例：处理摄像头帧\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # 转换为RGB并处理\n",
    "    image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(image_rgb)\n",
    "    \n",
    "    if results.multi_hand_landmarks:\n",
    "        hand_landmarks = results.multi_hand_landmarks[0]\n",
    "        img_size = (frame.shape[1], frame.shape[0])\n",
    "        \n",
    "        # 检测食指和中指是否重叠\n",
    "        is_overlap, top_finger = are_fingers_overlapping(\n",
    "            \"index\", \"middle\", hand_landmarks.landmark, img_size\n",
    "        )\n",
    "        \n",
    "        # 在图像上显示结果\n",
    "        if is_overlap:\n",
    "            text = f\"Overlap: {top_finger} on top\" if top_finger else \"Overlap: Uncertain\"\n",
    "            cv2.putText(frame, text, (50, 50), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    \n",
    "    cv2.imshow(\"Finger Overlap Detection\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e9beed",
   "metadata": {},
   "source": [
    "我能不能结合xy平面，xz平面，和zy平面进行推算？比如yz平面接近、zx平面其次的时候交叠就产生了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd4c238",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "\n",
    "# 初始化MediaPipe\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=True, max_num_hands=1, min_detection_confidence=0.7)\n",
    "\n",
    "# 指尖及关键关节点索引\n",
    "FINGER_TIPS = {\n",
    "    'thumb': 4, 'index': 8, 'middle': 12, 'ring': 16, 'pinky': 20\n",
    "}\n",
    "FINGER_BASES = {\n",
    "    'thumb': 2, 'index': 5, 'middle': 9, 'ring': 13, 'pinky': 17\n",
    "}\n",
    "\n",
    "def get_finger_bbox(finger_name, landmarks, img_size):\n",
    "    \"\"\"获取手指的包围盒（矩形区域）\"\"\"\n",
    "    tip = landmarks[FINGER_TIPS[finger_name]]\n",
    "    base = landmarks[FINGER_BASES[finger_name]]\n",
    "    w, h = img_size\n",
    "    \n",
    "    # 计算包围盒坐标（扩大10%避免边缘误差）\n",
    "    x_min = min(tip.x, base.x) * w * 0.9\n",
    "    x_max = max(tip.x, base.x) * w * 1.1\n",
    "    y_min = min(tip.y, base.y) * h * 0.9\n",
    "    y_max = max(tip.y, base.y) * h * 1.1\n",
    "    \n",
    "    return (x_min, y_min, x_max, y_max)\n",
    "\n",
    "def is_overlapping(finger1, finger2, landmarks, img_size):\n",
    "    \"\"\"判断两根手指是否空间重叠\"\"\"\n",
    "    # 获取两手指的包围盒\n",
    "    bbox1 = get_finger_bbox(finger1, landmarks, img_size)\n",
    "    bbox2 = get_finger_bbox(finger2, landmarks, img_size)\n",
    "    \n",
    "    # 检查包围盒交集（AABB碰撞检测）\n",
    "    no_overlap = (bbox1[2] < bbox2[0] or bbox1[0] > bbox2[2] or \n",
    "                  bbox1[3] < bbox2[1] or bbox1[1] > bbox2[3])\n",
    "    return not no_overlap\n",
    "\n",
    "def determine_finger_order(finger1, finger2, landmarks):\n",
    "    \"\"\"确定哪根手指在上（基于深度和几何关系）\"\"\"\n",
    "    tip1 = landmarks[FINGER_TIPS[finger1]]\n",
    "    tip2 = landmarks[FINGER_TIPS[finger2]]\n",
    "    \n",
    "    # 优先比较Z轴（直接深度信息）\n",
    "    if tip1.z < tip2.z - 0.05:  # finger1更靠近摄像头\n",
    "        return finger1\n",
    "    elif tip2.z < tip1.z - 0.05:  # finger2更靠近摄像头\n",
    "        return finger2\n",
    "    \n",
    "    # 若深度相近，检查手指角度（弯曲的手指更可能在上）\n",
    "    angle1 = abs(landmarks[FINGER_TIPS[finger1]].y - landmarks[FINGER_BASES[finger1]].y)\n",
    "    angle2 = abs(landmarks[FINGER_TIPS[finger2]].y - landmarks[FINGER_BASES[finger2]].y)\n",
    "    return finger1 if angle1 > angle2 else finger2\n",
    "\n",
    "# 示例：处理单张图片\n",
    "image = cv2.imread(\"your_image.jpg\")\n",
    "h, w = image.shape[:2]\n",
    "\n",
    "# 手部检测\n",
    "results = hands.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "if results.multi_hand_landmarks:\n",
    "    landmarks = results.multi_hand_landmarks[0].landmark\n",
    "    \n",
    "    # 检测所有可能的手指对\n",
    "    fingers = list(FINGER_TIPS.keys())\n",
    "    for i in range(len(fingers)):\n",
    "        for j in range(i+1, len(fingers)):\n",
    "            finger1, finger2 = fingers[i], fingers[j]\n",
    "            \n",
    "            if is_overlapping(finger1, finger2, landmarks, (w, h)):\n",
    "                top_finger = determine_finger_order(finger1, finger2, landmarks)\n",
    "                \n",
    "                # 在图像上标注结果\n",
    "                tip_pos = (int(landmarks[FINGER_TIPS[top_finger]].x * w), \n",
    "                          int(landmarks[FINGER_TIPS[top_finger]].y * h))\n",
    "                cv2.putText(image, f\"{top_finger} on top\", tip_pos,\n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)\n",
    "\n",
    "cv2.imshow(\"Result\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d93198f",
   "metadata": {},
   "source": [
    "The below code can recognize when index and middle finger are both on the top finger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f8109fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 67\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ret: \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     66\u001b[0m image_rgb \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(frame, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[1;32m---> 67\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mhands\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_rgb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m results\u001b[38;5;241m.\u001b[39mmulti_hand_landmarks:\n\u001b[0;32m     70\u001b[0m     hand_landmarks \u001b[38;5;241m=\u001b[39m results\u001b[38;5;241m.\u001b[39mmulti_hand_landmarks[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\mediapipe\\lib\\site-packages\\mediapipe\\python\\solutions\\hands.py:153\u001b[0m, in \u001b[0;36mHands.process\u001b[1;34m(self, image)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mprocess\u001b[39m(\u001b[38;5;28mself\u001b[39m, image: np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NamedTuple:\n\u001b[0;32m    133\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Processes an RGB image and returns the hand landmarks and handedness of each detected hand.\u001b[39;00m\n\u001b[0;32m    134\u001b[0m \n\u001b[0;32m    135\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;124;03m         right hand) of the detected hand.\u001b[39;00m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 153\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\mediapipe\\lib\\site-packages\\mediapipe\\python\\solution_base.py:340\u001b[0m, in \u001b[0;36mSolutionBase.process\u001b[1;34m(self, input_data)\u001b[0m\n\u001b[0;32m    334\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    335\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph\u001b[38;5;241m.\u001b[39madd_packet_to_input_stream(\n\u001b[0;32m    336\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream_name,\n\u001b[0;32m    337\u001b[0m         packet\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_packet(input_stream_type,\n\u001b[0;32m    338\u001b[0m                                  data)\u001b[38;5;241m.\u001b[39mat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_simulated_timestamp))\n\u001b[1;32m--> 340\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_until_idle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    341\u001b[0m \u001b[38;5;66;03m# Create a NamedTuple object where the field names are mapping to the graph\u001b[39;00m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;66;03m# output stream names.\u001b[39;00m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_stream_type_info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "\n",
    "# 初始化MediaPipe\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=True, max_num_hands=1, min_detection_confidence=0.7)\n",
    "\n",
    "# 指尖及第二关节索引（增强深度鲁棒性）\n",
    "FINGER_DATA = {\n",
    "    \"thumb\": {\"tip\": 4, \"joint\": 3},\n",
    "    \"index\": {\"tip\": 8, \"joint\": 7},\n",
    "    \"middle\": {\"tip\": 12, \"joint\": 11},\n",
    "    \"ring\": {\"tip\": 16, \"joint\": 15},\n",
    "    \"pinky\": {\"tip\": 20, \"joint\": 19}\n",
    "}\n",
    "\n",
    "def check_finger_overlap_3d(finger1, finger2, landmarks, img_size, \n",
    "                          xy_thresh=0.03, xz_thresh=0.05, yz_thresh=0.05):\n",
    "    \"\"\"\n",
    "    基于三维坐标的多平面重叠检测\n",
    "    :return: (是否重叠, 上方手指名称)\n",
    "    \"\"\"\n",
    "    # 获取指尖和第二关节的三维坐标（归一化）\n",
    "    def get_coords(finger):\n",
    "        tip = landmarks[FINGER_DATA[finger][\"tip\"]]\n",
    "        joint = landmarks[FINGER_DATA[finger][\"joint\"]]\n",
    "        return (tip.x, tip.y, tip.z), (joint.x, joint.y, joint.z)\n",
    "    \n",
    "    (tip1, joint1), (tip2, joint2) = get_coords(finger1), get_coords(finger2)\n",
    "    \n",
    "    # 计算多平面距离（归一化）\n",
    "    w, h = img_size\n",
    "    xy_dist = np.sqrt((tip1[0] - tip2[0])**2 + (tip1[1] - tip2[1])**2)  # XY平面\n",
    "    xz_dist = np.sqrt((tip1[0] - tip2[0])**2 + (tip1[2] - tip2[2])**2)  # XZ平面\n",
    "    yz_dist = np.sqrt((tip1[1] - tip2[1])**2 + (tip1[2] - tip2[2])**2)  # YZ平面\n",
    "    \n",
    "    # 检查是否在多平面接近\n",
    "    is_close_xy = xy_dist < xy_thresh\n",
    "    is_close_xz = xz_dist < xz_thresh\n",
    "    is_close_yz = yz_dist < yz_thresh\n",
    "    \n",
    "    # 判定逻辑：至少两个平面接近且XY平面必须接近\n",
    "    if is_close_xy and (is_close_xz or is_close_yz):\n",
    "        # 计算两根手指的均值深度（指尖+关节）\n",
    "        z1 = (tip1[2] + joint1[2]) / 2\n",
    "        z2 = (tip2[2] + joint2[2]) / 2\n",
    "        return True, finger1 if z1 < z2 else finger2\n",
    "    return False, None\n",
    "\n",
    "# 可视化\n",
    "def draw_overlap_result(frame, finger1, finger2, is_overlap, top_finger):\n",
    "    text = f\"{finger1}-{finger2}: \"\n",
    "    if is_overlap:\n",
    "        text += f\"Overlap ({top_finger} on top)\" if top_finger else \"Overlap (Uncertain)\"\n",
    "    else:\n",
    "        text += \"No overlap\"\n",
    "    cv2.putText(frame, text, (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)\n",
    "\n",
    "# 主循环\n",
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret: break\n",
    "    \n",
    "    image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(image_rgb)\n",
    "    \n",
    "    if results.multi_hand_landmarks:\n",
    "        hand_landmarks = results.multi_hand_landmarks[0]\n",
    "        img_size = (frame.shape[1], frame.shape[0])\n",
    "        \n",
    "        # 检测食指与中指（示例）\n",
    "        is_overlap, top_finger = check_finger_overlap_3d(\n",
    "            \"index\", \"middle\", hand_landmarks.landmark, img_size\n",
    "        )\n",
    "        draw_overlap_result(frame, \"Index\", \"Middle\", is_overlap, top_finger)\n",
    "    \n",
    "    cv2.imshow(\"3D Finger Overlap Detection\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == 27: break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd68c89f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb37488",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d980419d",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'finger_data\\\\finger_data.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 204\u001b[0m\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m模型已保存到 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMODEL_PATH\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;66;03m# 第一步：收集数据（如果已有数据可以跳过）\u001b[39;00m\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;66;03m# collect_data(num_samples=500)\u001b[39;00m\n\u001b[0;32m    202\u001b[0m     \n\u001b[0;32m    203\u001b[0m     \u001b[38;5;66;03m# 第二步：训练模型\u001b[39;00m\n\u001b[1;32m--> 204\u001b[0m     \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[8], line 148\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"训练重叠检测模型\"\"\"\u001b[39;00m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;66;03m# 加载数据\u001b[39;00m\n\u001b[1;32m--> 148\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDATA_DIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfinger_data.npz\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    149\u001b[0m X \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    150\u001b[0m y_overlap \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_overlap\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\mediapipe\\lib\\site-packages\\numpy\\lib\\npyio.py:427\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[0;32m    425\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    426\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 427\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    428\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    430\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'finger_data\\\\finger_data.npz'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# 初始化MediaPipe手部模型\n",
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=True, max_num_hands=1, min_detection_confidence=0.7)\n",
    "\n",
    "# 配置参数\n",
    "DATA_DIR = \"finger_data\"  # 数据存储目录\n",
    "MODEL_PATH = \"finger_overlap_model.pkl\"  # 模型保存路径\n",
    "FINGER_PAIRS = [(\"index\", \"middle\"), (\"thumb\", \"index\")]  # 要检测的手指组合\n",
    "TEST_SIZE = 0.2  # 测试集比例\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# 手指关键点索引配置\n",
    "FINGER_CONFIG = {\n",
    "    \"thumb\": [1, 2, 3, 4],   # 大拇指1-4号关键点\n",
    "    \"index\": [5, 6, 7, 8],    # 食指\n",
    "    \"middle\": [9, 10, 11, 12], # 中指\n",
    "    \"ring\": [13, 14, 15, 16],  # 无名指\n",
    "    \"pinky\": [17, 18, 19, 20]  # 小指\n",
    "}\n",
    "\n",
    "def extract_features(hand_landmarks, finger1, finger2):\n",
    "    \"\"\"从MediaPipe结果中提取两个手指的特征\"\"\"\n",
    "    # 获取两个手指的所有关键点（3D坐标）\n",
    "    f1_points = [hand_landmarks.landmark[i] for i in FINGER_CONFIG[finger1]]\n",
    "    f2_points = [hand_landmarks.landmark[i] for i in FINGER_CONFIG[finger2]]\n",
    "    \n",
    "    # 计算特征\n",
    "    features = []\n",
    "    \n",
    "    # 1. 指尖距离特征\n",
    "    tip1 = f1_points[-1]  # 指尖是每个手指的最后一个关键点\n",
    "    tip2 = f2_points[-1]\n",
    "    features.extend([\n",
    "        tip1.x - tip2.x,  # X轴差值\n",
    "        tip1.y - tip2.y,  # Y轴差值\n",
    "        tip1.z - tip2.z   # Z轴差值\n",
    "    ])\n",
    "    \n",
    "    # 2. 手指方向向量差异\n",
    "    vec1 = np.array([f1_points[-1].x - f1_points[0].x, \n",
    "                    f1_points[-1].y - f1_points[0].y,\n",
    "                    f1_points[-1].z - f1_points[0].z])\n",
    "    vec2 = np.array([f2_points[-1].x - f2_points[0].x,\n",
    "                    f2_points[-1].y - f2_points[0].y,\n",
    "                    f2_points[-1].z - f2_points[0].z])\n",
    "    features.extend(vec1 - vec2)\n",
    "    \n",
    "    # 3. 包围盒重叠特征\n",
    "    def get_bbox(points):\n",
    "        x = [p.x for p in points]\n",
    "        y = [p.y for p in points]\n",
    "        return min(x), max(x), min(y), max(y)\n",
    "    \n",
    "    f1_bbox = get_bbox(f1_points)\n",
    "    f2_bbox = get_bbox(f2_points)\n",
    "    features.extend([\n",
    "        max(0, min(f1_bbox[1], f2_bbox[1]) - max(f1_bbox[0], f2_bbox[0])),  # X轴重叠\n",
    "        max(0, min(f1_bbox[3], f2_bbox[3]) - max(f1_bbox[2], f2_bbox[2]))   # Y轴重叠\n",
    "    ])\n",
    "    \n",
    "    return features\n",
    "\n",
    "def collect_data(num_samples=1000):\n",
    "    \"\"\"收集训练数据\"\"\"\n",
    "    if not os.path.exists(DATA_DIR):\n",
    "        os.makedirs(DATA_DIR)\n",
    "    \n",
    "    # 初始化数据存储\n",
    "    X = []\n",
    "    y_overlap = []\n",
    "    y_top = []\n",
    "    \n",
    "    cap = cv2.VideoCapture(0)\n",
    "    sample_count = 0\n",
    "    \n",
    "    print(f\"正在收集数据，需要{num_samples}个样本...\")\n",
    "    print(\"请摆出不同手指重叠/不重叠的手势，按's'保存当前帧，按'q'退出\")\n",
    "    \n",
    "    while sample_count < num_samples:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            continue\n",
    "            \n",
    "        # 显示提示\n",
    "        cv2.putText(frame, f\"Collected: {sample_count}/{num_samples}\", (10, 30),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        cv2.putText(frame, \"Press 's' to save, 'q' to quit\", (10, 60),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)\n",
    "        \n",
    "        # 检测手部\n",
    "        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = hands.process(image_rgb)\n",
    "        \n",
    "        if results.multi_hand_landmarks:\n",
    "            hand_landmarks = results.multi_hand_landmarks[0]\n",
    "            \n",
    "            # 可视化手部关键点\n",
    "            mp.solutions.drawing_utils.draw_landmarks(\n",
    "                frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "            \n",
    "            cv2.imshow(\"Data Collection\", frame)\n",
    "            \n",
    "            key = cv2.waitKey(1)\n",
    "            if key == ord('s'):  # 保存样本\n",
    "                for f1, f2 in FINGER_PAIRS:\n",
    "                    features = extract_features(hand_landmarks, f1, f2)\n",
    "                    X.append(features)\n",
    "                    \n",
    "                    # 手动标注（实际应用中应该自动或半自动标注）\n",
    "                    print(f\"当前手指对: {f1} vs {f2}\")\n",
    "                    overlap = int(input(\"是否重叠？(0/1): \"))\n",
    "                    y_overlap.append(overlap)\n",
    "                    \n",
    "                    if overlap:\n",
    "                        top = int(input(f\"哪根手指在上？(0={f1}, 1={f2}): \"))\n",
    "                        y_top.append(top)\n",
    "                    else:\n",
    "                        y_top.append(-1)  # 无重叠标记为-1\n",
    "                \n",
    "                sample_count += 1\n",
    "                print(f\"已保存样本 {sample_count}/{num_samples}\")\n",
    "                \n",
    "            elif key == ord('q'):\n",
    "                break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    # 保存数据\n",
    "    np.savez(os.path.join(DATA_DIR, \"finger_data.npz\"),\n",
    "             X=np.array(X), \n",
    "             y_overlap=np.array(y_overlap),\n",
    "             y_top=np.array(y_top))\n",
    "    print(f\"数据已保存到 {DATA_DIR}\")\n",
    "\n",
    "def train_model():\n",
    "    \"\"\"训练重叠检测模型\"\"\"\n",
    "    # 加载数据\n",
    "    data = np.load(os.path.join(DATA_DIR, \"finger_data.npz\"))\n",
    "    X = data[\"X\"]\n",
    "    y_overlap = data[\"y_overlap\"]\n",
    "    y_top = data[\"y_top\"]\n",
    "    \n",
    "    # 划分训练集和测试集\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y_overlap, test_size=TEST_SIZE, random_state=RANDOM_STATE)\n",
    "    \n",
    "    # 训练重叠检测模型\n",
    "    overlap_model = RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=10,\n",
    "        class_weight=\"balanced\",\n",
    "        random_state=RANDOM_STATE\n",
    "    )\n",
    "    overlap_model.fit(X_train, y_train)\n",
    "    \n",
    "    # 评估重叠检测\n",
    "    print(\"\\n重叠检测模型性能:\")\n",
    "    print(classification_report(y_test, overlap_model.predict(X_test)))\n",
    "    \n",
    "    # 训练上下关系模型（仅使用重叠样本）\n",
    "    X_top = X[y_overlap == 1]\n",
    "    y_top = y_top[y_overlap == 1]\n",
    "    X_train_top, X_test_top, y_train_top, y_test_top = train_test_split(\n",
    "        X_top, y_top, test_size=TEST_SIZE, random_state=RANDOM_STATE)\n",
    "    \n",
    "    top_model = RandomForestClassifier(\n",
    "        n_estimators=50,\n",
    "        max_depth=5,\n",
    "        class_weight=\"balanced\",\n",
    "        random_state=RANDOM_STATE\n",
    "    )\n",
    "    top_model.fit(X_train_top, y_train_top)\n",
    "    \n",
    "    # 评估上下关系检测\n",
    "    print(\"\\n上下关系模型性能:\")\n",
    "    print(classification_report(y_test_top, top_model.predict(X_test_top)))\n",
    "    \n",
    "    # 保存模型\n",
    "    model = {\n",
    "        \"overlap_model\": overlap_model,\n",
    "        \"top_model\": top_model,\n",
    "        \"feature_names\": [\"tip_x_diff\", \"tip_y_diff\", \"tip_z_diff\",\n",
    "                         \"vec_x_diff\", \"vec_y_diff\", \"vec_z_diff\",\n",
    "                         \"bbox_x_overlap\", \"bbox_y_overlap\"]\n",
    "    }\n",
    "    joblib.dump(model, MODEL_PATH)\n",
    "    print(f\"\\n模型已保存到 {MODEL_PATH}\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     # 第一步：收集数据（如果已有数据可以跳过）\n",
    "#     # collect_data(num_samples=500)\n",
    "    \n",
    "#     # 第二步：训练模型\n",
    "#     train_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mediapipe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
